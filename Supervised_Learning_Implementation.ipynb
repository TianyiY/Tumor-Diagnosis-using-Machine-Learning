{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
      "0           ...                    25.38          17.33           184.60   \n",
      "1           ...                    24.99          23.41           158.80   \n",
      "2           ...                    23.57          25.53           152.50   \n",
      "3           ...                    14.91          26.50            98.87   \n",
      "4           ...                    22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  fractal_dimension_mean           ...             \\\n",
      "count     569.000000              569.000000           ...              \n",
      "mean        0.181162                0.062798           ...              \n",
      "std         0.027414                0.007060           ...              \n",
      "min         0.106000                0.049960           ...              \n",
      "25%         0.161900                0.057700           ...              \n",
      "50%         0.179200                0.061540           ...              \n",
      "75%         0.195700                0.066120           ...              \n",
      "max         0.304000                0.097440           ...              \n",
      "\n",
      "       radius_worst  texture_worst  perimeter_worst   area_worst  \\\n",
      "count    569.000000     569.000000       569.000000   569.000000   \n",
      "mean      16.269190      25.677223       107.261213   880.583128   \n",
      "std        4.833242       6.146258        33.602542   569.356993   \n",
      "min        7.930000      12.020000        50.410000   185.200000   \n",
      "25%       13.010000      21.080000        84.110000   515.300000   \n",
      "50%       14.970000      25.410000        97.660000   686.500000   \n",
      "75%       18.790000      29.720000       125.400000  1084.000000   \n",
      "max       36.040000      49.540000       251.200000  4254.000000   \n",
      "\n",
      "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count        569.000000         569.000000       569.000000   \n",
      "mean           0.132369           0.254265         0.272188   \n",
      "std            0.022832           0.157336         0.208624   \n",
      "min            0.071170           0.027290         0.000000   \n",
      "25%            0.116600           0.147200         0.114500   \n",
      "50%            0.131300           0.211900         0.226700   \n",
      "75%            0.146000           0.339100         0.382900   \n",
      "max            0.222600           1.058000         1.252000   \n",
      "\n",
      "       concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "count            569.000000      569.000000               569.000000  \n",
      "mean               0.114606        0.290076                 0.083946  \n",
      "std                0.065732        0.061867                 0.018061  \n",
      "min                0.000000        0.156500                 0.055040  \n",
      "25%                0.064930        0.250400                 0.071460  \n",
      "50%                0.099930        0.282200                 0.080040  \n",
      "75%                0.161400        0.317900                 0.092080  \n",
      "max                0.291000        0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the breast_cancer dataset from csv\n",
    "BC_Data = pd.read_csv('Cancer_Data.csv')\n",
    "\n",
    "# data visualization\n",
    "print BC_Data.head()\n",
    "Data=BC_Data.drop('id', axis=1)\n",
    "Feature=Data.drop('diagnosis', axis=1)\n",
    "print Feature.describe()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the training set modeled by LogisticRegression is 0.960093896714.\n",
      "the accuracy of the test set modeled by LogisticRegression is 0.958041958042.\n",
      "the F-score of the training set modeled by LogisticRegression is 0.96834264432.\n",
      "the F-score of the test set modeled by LogisticRegression is 0.965909090909.\n",
      "time consumption of LogisticRegression is {'training time': 0.004000186920166016, 'prediction time': 0.0}\n",
      "confusion matrix of training set of LogisticRegression is \n",
      "[[149  10]\n",
      " [  7 260]]\n",
      "confusion matrix of test set of LogisticRegression is \n",
      "[[52  1]\n",
      " [ 5 85]]\n",
      "the accuracy of the training set modeled by SVC is 1.0.\n",
      "the accuracy of the test set modeled by SVC is 0.629370629371.\n",
      "the F-score of the training set modeled by SVC is 1.0.\n",
      "the F-score of the test set modeled by SVC is 0.772532188841.\n",
      "time consumption of SVC is {'training time': 0.031000137329101562, 'prediction time': 0.03099989891052246}\n",
      "confusion matrix of training set of SVC is \n",
      "[[159   0]\n",
      " [  0 267]]\n",
      "confusion matrix of test set of SVC is \n",
      "[[ 0 53]\n",
      " [ 0 90]]\n",
      "the accuracy of the training set modeled by DecisionTreeClassifier is 1.0.\n",
      "the accuracy of the test set modeled by DecisionTreeClassifier is 0.881118881119.\n",
      "the F-score of the training set modeled by DecisionTreeClassifier is 1.0.\n",
      "the F-score of the test set modeled by DecisionTreeClassifier is 0.899408284024.\n",
      "time consumption of DecisionTreeClassifier is {'training time': 0.016000032424926758, 'prediction time': 0.0}\n",
      "confusion matrix of training set of DecisionTreeClassifier is \n",
      "[[159   0]\n",
      " [  0 267]]\n",
      "confusion matrix of test set of DecisionTreeClassifier is \n",
      "[[50  3]\n",
      " [14 76]]\n",
      "the accuracy of the training set modeled by RandomForestClassifier is 1.0.\n",
      "the accuracy of the test set modeled by RandomForestClassifier is 0.951048951049.\n",
      "the F-score of the training set modeled by RandomForestClassifier is 1.0.\n",
      "the F-score of the test set modeled by RandomForestClassifier is 0.96.\n",
      "time consumption of RandomForestClassifier is {'training time': 0.10000014305114746, 'prediction time': 0.031999826431274414}\n",
      "confusion matrix of training set of RandomForestClassifier is \n",
      "[[159   0]\n",
      " [  0 267]]\n",
      "confusion matrix of test set of RandomForestClassifier is \n",
      "[[52  1]\n",
      " [ 6 84]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Data_Process import Data_Process\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    # data preprocessing\n",
    "    X, Y=Data_Process().get_data()\n",
    "    X_train, X_test, y_train, y_test =Data_Process().data_split(X, Y)\n",
    "    \n",
    "    # perform four kinds of supervised machine learning algorithm on the data set\n",
    "    for smla in [LogisticRegression(random_state=0), SVC(random_state=0), DecisionTreeClassifier(random_state=0), RandomForestClassifier(random_state=0)]:\n",
    "        smla_name = smla.__class__.__name__\n",
    "        time_results={}    # for calculate the time efficiency\n",
    "\n",
    "        # data training\n",
    "        start1 = time()\n",
    "        smla.fit(X_train, y_train)\n",
    "        end1 = time()\n",
    "        time_results['training time'] = end1 - start1\n",
    "\n",
    "        # make prediction\n",
    "        start2 = time()\n",
    "        y_train_pred = smla.predict(X_train)\n",
    "        y_test_pred = smla.predict(X_test)\n",
    "        end2 = time()\n",
    "        time_results['prediction time'] = end2 - start2\n",
    "\n",
    "        # calculating the metrics\n",
    "        train_accuracy = 1.0 * np.mean(y_train_pred == y_train)\n",
    "        test_accuracy = 1.0 * np.mean(y_test_pred == y_test)\n",
    "        train_fscore = f1_score(y_train, y_train_pred)\n",
    "        test_fscore = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        # display the results\n",
    "        print 'the accuracy of the training set modeled by {} is {}.'.format(smla_name, train_accuracy) \n",
    "        print 'the accuracy of the test set modeled by {} is {}.'.format(smla_name, test_accuracy) \n",
    "        print 'the F-score of the training set modeled by {} is {}.'.format(smla_name, train_fscore) \n",
    "        print 'the F-score of the test set modeled by {} is {}.'.format(smla_name, test_fscore) \n",
    "\n",
    "        print 'time consumption of {} is {}'.format(smla_name, time_results)\n",
    "        print 'confusion matrix of training set of {} is \\n{}'.format(smla_name, confusion_matrix(y_train, y_train_pred))\n",
    "        print 'confusion matrix of test set of {} is \\n{}'.format(smla_name, confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
